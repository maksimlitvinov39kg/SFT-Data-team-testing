# Тестовое задание SFT-Data team

Большая часть современных open source VLM обучена на англоязычных датасетах и плохо знает культурные образы других регионов.

## Задание
1. Выбрать VLM исходя из имеющихся ресурсов.
2. Определить несколько региональных сущностей (например Чебурашка) и собрать датасет с ними.
3. Убедиться, что в данный момент, модель не распознает эти сущности.
4. Провести серию экспериментов по дообучению модели. Описать что именно было сделано и зачем.
5. Продемонстрировать и визуализировать результаты после обучения. Провести анализ, что получилось хорошо, что не получилось и почему.
6. Оформить код в репозиторий. Составить инструкцию каким образом можно протестировать дообучение на новых данных.

## Установка и настройка

### 1. Настройка окружения
Заполните файл `.env` своими API ключами и настройками:

```env
# API ключ для GigaChat (для caption генерации)
GIGACHAT_CREDENTIALS =y our_gigachat_api_key_here

# Scope для GigaChat
GIGACHAT_SCOPE=your_gigachat_scope_here

```

### 2. Установка зависимостей
```bash
pip install -r requirements.txt
```

## Запуск экспериментов

### 1. Подготовка данных
```bash
python caption_data.py
```
Этот скрипт создает  captions для изображений в датасете, используя GigaChat API.

### 2. Обучение модели
```bash
python train_qwen_lora.py
```
Запускает процесс дообучения выбранной VLM модели на подготовленном датасете.

### 3. Тестирование до обучения
Запустите notebook `test_pretrain.ipynb` для проверки качества модели до дообучения.

### 4. Тестирование после обучения
Запустите notebook `test_after_finetune_lora.ipynb` для оценки результатов дообучения и сравнения с исходной моделью.

## Добавление новых классов

Если вы хотите обучить модель на своем классе региональных сущностей:

1. Добавьте папку с изображениями в `data/images/<class_name>`
2. Добавьте пару `<название папки>: <название класса>` в файл `data/json/character_names.json`. Пример -
```json
"gena": "Крокодил Гена",
```
3. Запустите `caption_data.py` - он автоматически создаст описания только для новых изображений, которых еще нет в аннотациях

## Текущие проблемы

1. **Ограничения ресурсов**: 7B модели Qwen и LLaVA не помещаются в 24 ГБ памяти на MacBook M4 Pro. Используется Qwen-VL 3B как компромисс.

2. **Проблемы обучения**: 
   - Loss зависает на значении ~4 как на train, так и на validation
   - Качество генерации остается плохим
   - **Необходимо расширение датасета** для улучшения результатов

3. **Качество разметки**: Возможны проблемы с качеством caption'ов, поскольку GigaChat показывает посредственные результаты как caption-генератор, хотя и знает о русских культурных сущностях.

## Структура проекта

```
SFT-Data-team-testing/
├── data/
│   ├── images/          # Изображения для обучения
│   │   ├── alyosha/     # Изображения Алёши Поповича
│   │   ├── cheburashka/ # Изображения Чебурашки
│   │   ├── gena/        # Изображения крокодила Гены
│   │   └── kolobok/     # Изображения Колобка
│   ├── annotation.json # Разметка для обучения
│   └── json/
│       ├── base_prompts.json    # Базовые промпты
│       └── character_names.json # Названия персонажей

├── results/             # Результаты экспериментов
├── caption_data.py      # Скрипт для создания описаний
├── train_qwen_lora.py        # Скрипт обучения модели
├── test_pretrain.ipynb  # Тестирование до обучения
└── test_after_finetune_lora.ipynb # Тестирование после обучения
```
